{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZLyZ9_Cdrle"
   },
   "source": [
    "<h2 style='color:blue' align='center'>Transfer learning in image classification</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZxuG4z6drlg"
   },
   "source": [
    "**In this notebook we will use transfer learning and take pre-trained model from google's Tensorflow Hub and re-train that on flowers dataset. Using pre-trained model saves lot of time and computational budget for new classification problem at hand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Downloading protobuf-5.28.2-cp39-cp39-win_amd64.whl (431 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.21.5)\n",
      "Collecting tf-keras>=2.14.1\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow<2.18,>=2.17\n",
      "  Downloading tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "Collecting tensorflow-intel==2.17.0\n",
      "  Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Using cached protobuf-4.25.5-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Collecting keras>=3.2.0\n",
      "  Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Using cached ml_dtypes-0.4.1-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.12.1)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (21.3)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.42.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (4.1.1)\n",
      "Collecting numpy>=1.12.0\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting h5py>=3.10.0\n",
      "  Using cached h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (61.2.0)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.37.1)\n",
      "Collecting optree\n",
      "  Using cached optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.0.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.66.1-cp39-cp39-win_amd64.whl (4.3 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\91993\\\\anaconda3\\\\lib\\\\site-packages\\\\typing_extensions-4.1.1.dist-info\\\\METADATA'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Using cached tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\n",
      "jupyter-server 1.13.5 requires pywinpty<2; os_name == \"nt\", but you have pywinpty 2.0.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras>=2.14.1\n",
      "  Using cached tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Using cached protobuf-5.28.2-cp39-cp39-win_amd64.whl (431 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.21.5)\n",
      "Collecting tensorflow<2.18,>=2.17\n",
      "  Using cached tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "Collecting tensorflow-intel==2.17.0\n",
      "  Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1\n",
      "  Downloading ml_dtypes-0.4.1-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Collecting keras>=3.2.0\n",
      "  Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (4.1.1)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.27.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.12.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting h5py>=3.10.0\n",
      "  Downloading h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (21.3)\n",
      "Collecting numpy>=1.12.0\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.42.0)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Downloading protobuf-4.25.5-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (61.2.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (0.37.1)\n",
      "Collecting rich\n",
      "  Downloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.12.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (1.26.9)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.3.4)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.66.1-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (2.0.3)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\91993\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras>=2.14.1->tensorflow_hub) (3.0.4)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, typing-extensions, pygments, numpy, markdown-it-py, tensorboard-data-server, rich, protobuf, optree, namex, ml-dtypes, h5py, grpcio, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow, tf-keras, tensorflow-hub\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.1.1\n",
      "    Uninstalling typing-extensions-4.1.1:\n",
      "      Successfully uninstalled typing-extensions-4.1.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.6.0\n",
      "    Uninstalling h5py-3.6.0:\n",
      "      Successfully uninstalled h5py-3.6.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.5 pygments-2.18.0 rich-13.8.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-hub-0.16.1 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 tf-keras-2.17.0 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qnSOIslVdrlj"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mImage\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import PIL as PIL\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2wQzUgedrlk"
   },
   "source": [
    "**Make predictions using ready made model (without any training)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lAOzRRTdrlk"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "6oYv9NYAdrlk",
    "outputId": "05c6cdbe-cf45-49dd-8277-569d35d9ce03",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gold_fish = Image.open(\"goldfish.jpg\").resize(IMAGE_SHAPE)\n",
    "gold_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBlwC3mxdrll",
    "outputId": "37e43362-f937-4115-c916-782c400b019f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gold_fish = np.array(gold_fish)/255.0\n",
    "gold_fish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gT5JDFDMdrll",
    "outputId": "d521144c-c108-42cf-bf5b-fcf7eefdd199"
   },
   "outputs": [],
   "source": [
    "gold_fish[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=gold_fish[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6Ffphcvdrlm",
    "outputId": "de1aac95-0e89-415d-83ac-4e8fd105eb94"
   },
   "outputs": [],
   "source": [
    "result = classifier.predict(gold_fish[np.newaxis, ...])\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34OE33hUdrlm",
    "outputId": "31d76b93-47f9-40fe-d6f3-599ed0984f94"
   },
   "outputs": [],
   "source": [
    "predicted_label_index = np.argmax(result)\n",
    "predicted_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nT4aTjYidrlm",
    "outputId": "2e77554d-1693-4b3a-faed-bd3a575837e1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "image_labels = []\n",
    "with open(\"ImageNetLabels.txt\", \"r\") as f:\n",
    "    image_labels = f.read().splitlines()\n",
    "image_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ovVCX61Mdrln",
    "outputId": "4a0550a0-ad23-4b6a-c683-ac9b810c0b2b"
   },
   "outputs": [],
   "source": [
    "image_labels[predicted_label_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKSyB8rkdrlo"
   },
   "source": [
    "<h3 style='color:purple'>Load flowers dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHYAkhumdrlo",
    "outputId": "2dd47a00-2453-4c7e-9e67-0c800180462e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n",
    "# cache_dir indicates where to download data. I specified . which means current directory\n",
    "# untar true will unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NFxl-PSrdrlo",
    "outputId": "ceac9f4c-206f-4e89-c1e7-42ff2e35003e"
   },
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAyMWLm1drlp",
    "outputId": "9469000c-a64b-4fc4-9809-fee0067059f6"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3IPMCdGdrlp",
    "outputId": "65078fb4-3f30-4ba1-8a5c-988ef364615b"
   },
   "outputs": [],
   "source": [
    "list(data_dir.glob('*/*.jpg'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KspXoEO1drlq",
    "outputId": "04ce8fcb-0ebf-41ab-d181-0b6160f94ed5"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "451iO_Yldrlq",
    "outputId": "bd796cd7-38d4-47ec-dabb-dfd5d6a6927e"
   },
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "roses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "cpAPWL77drlq",
    "outputId": "d2004d63-f337-4757-b4ad-5683ac3c2e9b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "STUec3i4drlr",
    "outputId": "d13046e0-4870-449f-9e42-1b3fedde5719",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tulips = list(data_dir.glob('tulips/*'))\n",
    "PIL.Image.open(str(tulips[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htbHBL2Ndrlr"
   },
   "source": [
    "<h3 style='color:purple'>Read flowers images from disk into numpy array using opencv</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5IRlzCwdrlr"
   },
   "outputs": [],
   "source": [
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'daisy': list(data_dir.glob('daisy/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips': list(data_dir.glob('tulips/*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD2HRHAddrls"
   },
   "outputs": [],
   "source": [
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIr0pw0mdrls",
    "outputId": "2e349403-e35e-428b-bc5a-77f60e3b6c3f"
   },
   "outputs": [],
   "source": [
    "flowers_images_dict['roses'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aFWv3I7rdrls",
    "outputId": "3f5a618c-078a-4be0-f43e-d7a521ecf3fe"
   },
   "outputs": [],
   "source": [
    "str(flowers_images_dict['roses'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGB1ZB9bdrls"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(str(flowers_images_dict['roses'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7bLJc4ydrlt",
    "outputId": "4bd7854f-91a2-4f1e-8ffd-8f756e940e1f"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqQ_jPc7drlt",
    "outputId": "445804d9-c703-4ffb-a751-13f261d91c5f"
   },
   "outputs": [],
   "source": [
    "cv2.resize(img,(224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0lYvlhMdrlt"
   },
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for flower_name, images in flowers_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img,(224,224))\n",
    "        X.append(resized_img)\n",
    "        y.append(flowers_labels_dict[flower_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdAwzFM_drlt"
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS_Aff6Pdrlu"
   },
   "source": [
    "<h3 style='color:purple'>Train test split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de6let-Wdrlu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txNOtvWcdrlu"
   },
   "source": [
    "<h3 style='color:purple'>Preprocessing: scale images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bHHUMtYdrlu"
   },
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1Aeoh4jdrlv"
   },
   "source": [
    "**Make prediction using pre-trained model on new flowers dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gu7jRwP_drlv",
    "outputId": "fc1e5319-f1f0-437d-f014-017517267f86"
   },
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BA5EuANdrlv",
    "outputId": "ec88b7e0-5659-4371-bcb9-828c146e558c"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE+(3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trOqRUH8drlv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0_resized = cv2.resize(X[0], IMAGE_SHAPE)\n",
    "x1_resized = cv2.resize(X[1], IMAGE_SHAPE)\n",
    "x2_resized = cv2.resize(X[2], IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Q-POKk5idrlw",
    "outputId": "5800d1ab-289c-47f1-cdef-db4ed9c412c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "n1PF7GtEdrlw",
    "outputId": "e52d5a1b-cd6d-4e25-8c3e-64666140f023"
   },
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "uRwAPR0tdrlw",
    "outputId": "6f8493fb-fb5f-4ef7-ce7f-d3a9daa43a97"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfcvLiCUdrlw",
    "outputId": "509eeee6-b394-4e98-ce20-de3be0601bc0"
   },
   "outputs": [],
   "source": [
    "predicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5W8OCT10drlx",
    "outputId": "f61ac93c-b2a5-4021-8ecb-dd35b15571ff"
   },
   "outputs": [],
   "source": [
    "image_labels[795]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05s2oYrtdrlx"
   },
   "source": [
    "<h3 style='color:purple'>Now take pre-trained model and retrain it using flowers images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pv603Rwpdrlx"
   },
   "outputs": [],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwP0IX2Udrlx",
    "outputId": "82c8a54f-d315-4f31-a0c4-6c819462c9ee"
   },
   "outputs": [],
   "source": [
    "num_of_flowers = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  pretrained_model_without_top_layer,\n",
    "  tf.keras.layers.Dense(num_of_flowers)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inb0tViCdrly",
    "outputId": "c2c67e22-3caa-46b9-c20a-461353431648"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooUwpdDZdrly",
    "outputId": "aad0e6c4-cec7-44c4-e456-44d044926d26"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize to [0, 1] range\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'daisy.jpg'\n",
    "test_image = preprocess_image(test_image_path)\n",
    "predictions = model.predict(test_image)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "# Example class names (should match your dataset structure)\n",
    "class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "print(f\"Predicted flower: {class_names[predicted_class[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn_transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
